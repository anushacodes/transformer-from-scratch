{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import create_transformer_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_raw = \"../data/english.txt\"\n",
    "fr_raw = \"../data/french.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<SOS>'\n",
    "PADDING_TOKEN = '<PAD>' # Used for padding and ignored in loss\n",
    "END_TOKEN = '<EOS>'\n",
    "UNKNOWN_TOKEN = '<UNK>' # For handling unknown chars during evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_french_chars = [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                     '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                     ':', '<', '=', '>', '?', '@', \n",
    "                     'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', \n",
    "                     'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', \n",
    "                     'Y', 'Z',\n",
    "                     '[', '\\\\', ']', '^', '_', '`', \n",
    "                     'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                     'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                     'y', 'z', \n",
    "                     '{', '|', '}', '~',\n",
    "                     'à', 'â', 'ä', 'æ', 'ç', 'é', 'è', 'ê', 'ë', 'î', 'ï', 'ô', 'œ', 'ù', 'û', 'ü', 'ÿ',\n",
    "                     'À', 'Â', 'Ä', 'Æ', 'Ç', 'É', 'È', 'Ê', 'Ë', 'Î', 'Ï', 'Ô', 'Œ', 'Ù', 'Û', 'Ü', 'Ÿ',\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_english_chars = [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@', \n",
    "                        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', \n",
    "                        'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', \n",
    "                        'Y', 'Z',\n",
    "                        '[', '\\\\', ']', '^', '_', '`', \n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                        'y', 'z', \n",
    "                        '{', '|', '}', '~']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADDING_TOKEN usually gets index 0\n",
    "french_vocabulary = [PADDING_TOKEN, START_TOKEN, END_TOKEN, UNKNOWN_TOKEN] + base_french_chars\n",
    "english_vocabulary = [PADDING_TOKEN, START_TOKEN, END_TOKEN, UNKNOWN_TOKEN] + base_english_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(en_raw, 'r') as file:\n",
    "    en_sentences = file.readlines()\n",
    "with open(fr_raw, 'r') as file:\n",
    "    fr_sentences = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentences = [sentence.rstrip('\\n') for sentence in en_sentences]\n",
    "fr_sentences = [sentence.rstrip('\\n') for sentence in fr_sentences]\n",
    "\n",
    "# Removes the narrow non-breaking space (\\u202f) and replace it with a normal space\n",
    "fr_sentences = [sentence.replace('\\u202f', ' ') for sentence in fr_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: ['Go.', 'Hi.', 'Hi.', 'Run!', 'Run!', 'Who?', 'Wow!', 'Fire!', 'Help!', 'Jump.'] \n",
      "French: ['Va !', 'Salut !', 'Salut.', 'Cours !', 'Courez !', 'Qui ?', 'Ça alors !', 'Au feu !', \"À l'aide !\", 'Saute.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"English: {en_sentences[:10]} \\nFrench: {fr_sentences[:10]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_fr = {k:v for k,v in enumerate(french_vocabulary)}\n",
    "fr_to_index = {v:k for k,v in enumerate(french_vocabulary)}\n",
    "index_to_en = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "en_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding Index (Ignore Loss / FR Pad): 0\n",
      "EN Padding Index: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Define Padding Index Constant ---\n",
    "# IMPORTANT: This index must match the PADDING_TOKEN position in vocab\n",
    "IGNORE_IDX = fr_to_index[PADDING_TOKEN] # Used for loss function\n",
    "EN_PADDING_IDX = en_to_index[PADDING_TOKEN] # Used for padding source batches\n",
    "FR_PADDING_IDX = fr_to_index[PADDING_TOKEN] # Used for padding target batches\n",
    "# Verify these are likely 0 if PADDING_TOKEN is first in vocab list\n",
    "print(f\"Padding Index (Ignore Loss / FR Pad): {IGNORE_IDX}\")\n",
    "print(f\"EN Padding Index: {EN_PADDING_IDX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOTAL_SENTENCES = 400000\n",
    "en = en_sentences[:]\n",
    "fr = fr_sentences[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170651 sentences\n",
      "['Go.', 'Hi.', 'Hi.', 'Run!', 'Run!', 'Who?', 'Wow!', 'Fire!', 'Help!', 'Jump.']\n",
      "['Va !', 'Salut !', 'Salut.', 'Cours !', 'Courez !', 'Qui ?', 'Ça alors !', 'Au feu !', \"À l'aide !\", 'Saute.']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(en)} sentences\")\n",
    "print(en[:10])\n",
    "print(fr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 286)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(x) for x in fr), max(len(x) for x in en),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99th percentile length french: 85.0\n",
      "99th percentile length English: 70.0\n"
     ]
    }
   ],
   "source": [
    "PERCENTILE = 99\n",
    "print( f\"{PERCENTILE}th percentile length french: {np.percentile([len(x) for x in fr], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in en], PERCENTILE)}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 170651\n",
      "Number of valid sentences: 164317\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 100\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(fr)):\n",
    "    french_sentence, english_sentence = fr[index], en[index]\n",
    "    if is_valid_length(french_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(french_sentence, french_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(fr)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "french = [fr[i] for i in valid_sentence_indicies]\n",
    "english = [en[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164317"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english)\n",
    "#164317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Va !',\n",
       " \"Quiconque l'a-t-il remarqué ?\",\n",
       " 'Nous parlâmes de divers sujets.',\n",
       " 'Le match fut annulé à cause de la pluie.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french[::50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.',\n",
       " 'Did anybody notice this?',\n",
       " 'We talked about various topics.',\n",
       " 'The game was called off on account of the rain.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english[::50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = create_transformer_model(\n",
    "    src_vocab_size=len(english_vocabulary),\n",
    "    tgt_vocab_size=len(french_vocabulary),\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    d_ff=2048,\n",
    "    max_seq_len= 100,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (src_embedding): Embedding(98, 512)\n",
       "  (tgt_embedding): Embedding(132, 512)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-2): 3 x EncoderLayer(\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-2): 3 x DecoderLayer(\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (cross_attention): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_linear): Linear(in_features=512, out_features=132, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 22,254,724\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable parameters: {count_parameters(transformer):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 147885, Validation samples: 16432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filtered_english = [en[i] for i in valid_sentence_indicies]\n",
    "filtered_french = [fr[i] for i in valid_sentence_indicies]\n",
    "\n",
    "# 90% train, 10% validation\n",
    "train_english, val_english, train_french, val_french = train_test_split(\n",
    "    filtered_english, filtered_french, test_size=0.1, random_state=42 \n",
    ")\n",
    "print(f\"Training samples: {len(train_english)}, Validation samples: {len(val_english)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, vocab):\n",
    "    return [char for char in sentence if char in vocab]\n",
    "\n",
    "class TextDataset(Dataset): \n",
    "    def __init__(self, english, french, en_to_index, fr_to_index):\n",
    "        self.english = english\n",
    "        self.french = french\n",
    "        self.en_to_index = en_to_index\n",
    "        self.fr_to_index = fr_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_sentence, french_sentence = self.english[idx], self.french[idx]\n",
    "\n",
    "        eng_tokenized = [START_TOKEN] + tokenize(eng_sentence, english_vocabulary) + [END_TOKEN]\n",
    "        fr_tokenized = [START_TOKEN] + tokenize(french_sentence, french_vocabulary) + [END_TOKEN]\n",
    "\n",
    "        eng_numericalized = [self.en_to_index[token] for token in eng_tokenized]\n",
    "        fr_numericalized = [self.fr_to_index[token] for token in fr_tokenized]\n",
    "        return torch.tensor(eng_numericalized), torch.tensor(fr_numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_english, train_french, en_to_index, fr_to_index)\n",
    "val_dataset = TextDataset(val_english, val_french, en_to_index, fr_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_batch(batch, en_padding_idx, fr_padding_idx): # Accept indices\n",
    "    src_list, tgt_list = zip(*batch)\n",
    "    # Check if lists are empty before calculating max\n",
    "    if not src_list or not tgt_list:\n",
    "         return torch.empty(0), torch.empty(0) # Or handle as appropriate\n",
    "\n",
    "    src_max_len = max(src.size(0) for src in src_list) if src_list else 0\n",
    "    tgt_max_len = max(tgt.size(0) for tgt in tgt_list) if tgt_list else 0\n",
    "\n",
    "    padded_src_list = []\n",
    "    padded_tgt_list = []\n",
    "    for src, tgt in zip(src_list, tgt_list):\n",
    "        pad_len_src = src_max_len - src.size(0)\n",
    "        pad_len_tgt = tgt_max_len - tgt.size(0)\n",
    "        # Use the passed indices directly\n",
    "        padded_src = F.pad(src, (0, pad_len_src), value=en_padding_idx)\n",
    "        padded_tgt = F.pad(tgt, (0, pad_len_tgt), value=fr_padding_idx)\n",
    "        padded_src_list.append(padded_src)\n",
    "        padded_tgt_list.append(padded_tgt)\n",
    "\n",
    "    # Only stack if lists are not empty\n",
    "    final_src = torch.stack(padded_src_list) if padded_src_list else torch.empty(0)\n",
    "    final_tgt = torch.stack(padded_tgt_list) if padded_tgt_list else torch.empty(0)\n",
    "    return final_src, final_tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          collate_fn=lambda batch: padding_batch(batch, EN_PADDING_IDX, FR_PADDING_IDX),\n",
    "                          drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        collate_fn=lambda batch: padding_batch(batch, EN_PADDING_IDX, FR_PADDING_IDX),\n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=IGNORE_IDX) # Use the defined constant\n",
    "optim = torch.optim.AdamW(transformer.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "clip_grad_norm = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, target, criterion):\n",
    "\n",
    "    # Output: [batch_size * seq_len, vocab_size]\n",
    "    # Target: [batch_size * seq_len]\n",
    "    output_flat = output.contiguous().view(-1, output.shape[-1])\n",
    "    target_flat = target.contiguous().view(-1)\n",
    "\n",
    "    # Criterion handles ignoring padding index and reduction (usually mean)\n",
    "    loss = criterion(output_flat, target_flat)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: mps\n",
      "--- Epoch 1/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   4%|▍         | 200/4621 [03:54<38:32,  1.91it/s, batch_loss=2.1278]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 200 Loss: 2.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   4%|▍         | 201/4621 [04:17<9:07:20,  7.43s/it, batch_loss=2.1278]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Quellle de de de de de de ?re ?re ?le ?le ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   9%|▊         | 400/4621 [06:05<29:09,  2.41it/s, batch_loss=1.8342]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 400 Loss: 1.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   9%|▊         | 401/4621 [06:10<2:00:09,  1.71s/it, batch_loss=1.8342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Combien avous avous avent ce ?re ?re ? ? ?re ?ure ?re ?ure ? ? ?re ?re ?un ?re ?re ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  13%|█▎        | 600/4621 [07:46<38:30,  1.74it/s, batch_loss=1.7987]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 600 Loss: 1.7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  13%|█▎        | 601/4621 [07:50<2:03:25,  1.84s/it, batch_loss=1.7987]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Quelle est en pas as le tre ?re ?r ? ? ? ?re ?res ?r?re ? ? ?res ?re ?re ?re ?re ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  17%|█▋        | 800/4621 [09:27<31:39,  2.01it/s, batch_loss=1.6200]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 800 Loss: 1.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  17%|█▋        | 801/4621 [09:31<1:48:12,  1.70s/it, batch_loss=1.6200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Quelle est le mont le mon pas le mon ?e ? ?e ?e ?e ?le ?on ?e ? ?e ?e ? ?e ?e ?re ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  22%|██▏       | 1000/4621 [11:16<31:42,  1.90it/s, batch_loss=1.5447] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1000 Loss: 1.5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  22%|██▏       | 1001/4621 [11:20<1:56:18,  1.93s/it, batch_loss=1.5447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Pourquoi ais-tu le main ? ?a ? ?a ? ? ? ?a ?ailere ?e ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  26%|██▌       | 1200/4621 [12:55<43:51,  1.30it/s, batch_loss=1.4542]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1200 Loss: 1.4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  26%|██▌       | 1201/4621 [12:59<1:45:58,  1.86s/it, batch_loss=1.4542]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Est-ce que tu ais avec de chanter ? ? ? ?e ??e ?e ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  30%|███       | 1400/4621 [24:28<25:39,  2.09it/s, batch_loss=1.4259]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1400 Loss: 1.4259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  30%|███       | 1401/4621 [24:32<1:30:36,  1.69s/it, batch_loss=1.4259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Avez-vous de ma cher ? ? ?a ? ? ? ? ? ??? ???\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  35%|███▍      | 1600/4621 [26:01<23:07,  2.18it/s, batch_loss=1.3853]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1600 Loss: 1.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  35%|███▍      | 1601/4621 [26:05<1:21:58,  1.63s/it, batch_loss=1.3853]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Comment le mont de te prop ?our ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  39%|███▉      | 1800/4621 [27:57<27:22,  1.72it/s, batch_loss=1.2294]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1800 Loss: 1.2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  39%|███▉      | 1801/4621 [28:01<1:21:40,  1.74s/it, batch_loss=1.2294]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Pourquoi le m'aider l'autre ? ???\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  43%|████▎     | 2000/4621 [29:37<24:31,  1.78it/s, batch_loss=1.2871]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2000 Loss: 1.2871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  43%|████▎     | 2001/4621 [29:41<1:17:07,  1.77s/it, batch_loss=1.2871]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Aucun devrais-tu de me dire ?0000000000000000000000000000000 ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  48%|████▊     | 2200/4621 [31:19<16:10,  2.50it/s, batch_loss=1.2373]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2200 Loss: 1.2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  48%|████▊     | 2201/4621 [31:24<1:12:21,  1.79s/it, batch_loss=1.2373]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): De me demander le me faire ? ? ? ? ? ? ?le ?e le ?la ?e ?e ?a ?aila ?la ?a ?a ?la \n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  52%|█████▏    | 2400/4621 [33:03<15:59,  2.31it/s, batch_loss=1.1846]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2400 Loss: 1.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  52%|█████▏    | 2401/4621 [33:07<1:02:58,  1.70s/it, batch_loss=1.1846]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): De la maison de la maison ?ourd ??\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  56%|█████▋    | 2600/4621 [34:45<20:36,  1.63it/s, batch_loss=1.2816]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2600 Loss: 1.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  56%|█████▋    | 2601/4621 [34:50<1:09:41,  2.07s/it, batch_loss=1.2816]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): La mois-tu aller ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  61%|██████    | 2800/4621 [36:36<18:03,  1.68it/s, batch_loss=1.1817]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2800 Loss: 1.1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  61%|██████    | 2801/4621 [36:41<1:02:09,  2.05s/it, batch_loss=1.1817]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Dites-ce que je veux parler ? ? ? ? ? ? ? ? ? ? ?a ? ?a ? ? ?ai ? ? ? ?ai ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  65%|██████▍   | 3000/4621 [38:34<14:18,  1.89it/s, batch_loss=1.2006]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3000 Loss: 1.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  65%|██████▍   | 3001/4621 [38:39<56:07,  2.08s/it, batch_loss=1.2006]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Voudriez-vous de me dire ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  69%|██████▉   | 3200/4621 [40:31<11:43,  2.02it/s, batch_loss=1.3065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3200 Loss: 1.3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  69%|██████▉   | 3201/4621 [40:36<48:38,  2.06s/it, batch_loss=1.3065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Dis-nous le montrer ? ? ? ? ? ? ? ? ? ? ?ous ? ? ?ous ? ? ?ou ? ? ?ou ?l'ai\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  74%|███████▎  | 3400/4621 [42:29<11:21,  1.79it/s, batch_loss=1.2233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3400 Loss: 1.2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  74%|███████▎  | 3401/4621 [42:35<50:41,  2.49s/it, batch_loss=1.2233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Dis-tu ce que ce soit ? Tom ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  78%|███████▊  | 3600/4621 [45:02<12:36,  1.35it/s, batch_loss=1.0117]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3600 Loss: 1.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  78%|███████▊  | 3601/4621 [45:07<40:08,  2.36s/it, batch_loss=1.0117]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Dis-moi commencer ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  82%|████████▏ | 3800/4621 [47:04<07:46,  1.76it/s, batch_loss=1.0356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3800 Loss: 1.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  82%|████████▏ | 3801/4621 [47:09<27:30,  2.01s/it, batch_loss=1.0356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrais-tu quelque chose ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  87%|████████▋ | 4000/4621 [48:59<05:30,  1.88it/s, batch_loss=1.1064]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4000 Loss: 1.1064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  87%|████████▋ | 4001/4621 [49:04<19:11,  1.86s/it, batch_loss=1.1064]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Dis-moi ce que je me rendre ? ? ? ? ? ? ? ?a ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  91%|█████████ | 4200/4621 [50:47<03:34,  1.96it/s, batch_loss=1.1734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4200 Loss: 1.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  91%|█████████ | 4201/4621 [50:51<12:08,  1.73s/it, batch_loss=1.1734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Tout le monde partir le manger ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  95%|█████████▌| 4400/4621 [52:45<01:40,  2.20it/s, batch_loss=1.1094]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4400 Loss: 1.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:  95%|█████████▌| 4401/4621 [52:50<06:44,  1.84s/it, batch_loss=1.1094]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Trai au moins de la maison ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|█████████▉| 4600/4621 [54:30<00:09,  2.25it/s, batch_loss=0.8502]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4600 Loss: 0.8502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|█████████▉| 4601/4621 [54:34<00:35,  1.77s/it, batch_loss=0.8502]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Dites-moi aller le montement ? ? ? ?ous ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 4621/4621 [54:44<00:00,  1.41it/s, batch_loss=0.8715]\n",
      "Validation: 100%|██████████| 513/513 [01:33<00:00,  5.50it/s, val_loss=0.939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary: Avg Train Loss: 1.3595, Avg Val Loss: 0.9313\n",
      "--- Epoch 2/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:   4%|▍         | 200/4621 [01:53<39:38,  1.86it/s, batch_loss=1.0956]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 200 Loss: 1.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:   4%|▍         | 201/4621 [01:58<2:23:22,  1.95s/it, batch_loss=1.0956]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Demainde-tu ce qui est la maison ? ? ? ? ? ? ? ?a ? ?a ?a ? ? ?a ? ? ? ?a ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:   9%|▊         | 400/4621 [03:41<35:00,  2.01it/s, batch_loss=0.8570]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 400 Loss: 0.8570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:   9%|▊         | 401/4621 [03:46<2:08:46,  1.83s/it, batch_loss=0.8570]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Sortez-vous la plus laisse ? ? ? ? ? ? ? ? ? ? ? ? ?ou ? ? ? ? ? ?ou ?a ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  13%|█▎        | 600/4621 [05:27<36:03,  1.86it/s, batch_loss=1.0272]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 600 Loss: 1.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  13%|█▎        | 601/4621 [05:31<2:00:52,  1.80s/it, batch_loss=1.0272]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrait-il quelque chose ? ? ? ? ? ? ? ? ? ? ? ? ?a ?a ? ? ?a ? ? ?a ?ai ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  17%|█▋        | 800/4621 [07:15<28:22,  2.24it/s, batch_loss=1.0387]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 800 Loss: 1.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  17%|█▋        | 801/4621 [07:19<1:49:20,  1.72s/it, batch_loss=1.0387]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrait-il le temps ? ? ? ? ? ? ? ? ? ? ? ? ?ous ? ? ? ? ? ? ? ? ? ? \n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  22%|██▏       | 1000/4621 [09:00<30:58,  1.95it/s, batch_loss=0.8755] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1000 Loss: 0.8755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  22%|██▏       | 1001/4621 [09:05<1:57:51,  1.95s/it, batch_loss=0.8755]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrions-nous la maison ? ? ? ? ? ? ? ? ? ? ? ?ous ? ?on ? ?ou ? ? ?ous ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  26%|██▌       | 1200/4621 [10:50<42:46,  1.33it/s, batch_loss=0.9993]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1200 Loss: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  26%|██▌       | 1201/4621 [10:56<2:04:06,  2.18s/it, batch_loss=0.9993]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): La vie de la plus laisse ? ? ? ? ? ? ? ? ? ? ?ou ? ?ou ? ?ou ? ? ?ou ? ? \n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  30%|███       | 1400/4621 [12:53<27:39,  1.94it/s, batch_loss=0.8875]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1400 Loss: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  30%|███       | 1401/4621 [12:58<1:47:19,  2.00s/it, batch_loss=0.8875]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrions-nous aller la maison ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  35%|███▍      | 1600/4621 [15:02<31:18,  1.61it/s, batch_loss=0.9212]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1600 Loss: 0.9212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  35%|███▍      | 1601/4621 [15:07<1:45:49,  2.10s/it, batch_loss=0.9212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrait-il le temps la maison ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  39%|███▉      | 1800/4621 [17:01<25:27,  1.85it/s, batch_loss=0.9322]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 1800 Loss: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  39%|███▉      | 1801/4621 [17:05<1:31:23,  1.94s/it, batch_loss=0.9322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrions-nous le plus tard ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  43%|████▎     | 2000/4621 [18:59<25:03,  1.74it/s, batch_loss=0.9269]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2000 Loss: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  43%|████▎     | 2001/4621 [19:04<1:26:40,  1.98s/it, batch_loss=0.9269]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Diter la maison de la maison ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  48%|████▊     | 2200/4621 [20:48<24:12,  1.67it/s, batch_loss=0.8929]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2200 Loss: 0.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  48%|████▊     | 2201/4621 [20:53<1:19:49,  1.98s/it, batch_loss=0.8929]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrai-moi le perdre la maison ? ? soit ? ? ? ?out ? ?out ? ? ?out ? ? ?outout ? \n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  52%|█████▏    | 2400/4621 [22:33<17:53,  2.07it/s, batch_loss=0.8656]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2400 Loss: 0.8656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  52%|█████▏    | 2401/4621 [22:38<1:06:54,  1.81s/it, batch_loss=0.8656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrions-nous aller la maison ? ? ? ? ? ? ? ?out ? ? ?ou ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  56%|█████▋    | 2600/4621 [24:25<16:59,  1.98it/s, batch_loss=0.7910]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2600 Loss: 0.7910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  56%|█████▋    | 2601/4621 [24:30<1:09:00,  2.05s/it, batch_loss=0.7910]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): De nous allerons la vie ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  61%|██████    | 2800/4621 [26:16<14:27,  2.10it/s, batch_loss=0.8722]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 2800 Loss: 0.8722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  61%|██████    | 2801/4621 [26:21<59:15,  1.95s/it, batch_loss=0.8722]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Serait-il de la maison ? ? ? ? ? ? ?out ? ?oute ?oute ?oute ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  65%|██████▍   | 3000/4621 [28:10<14:19,  1.89it/s, batch_loss=0.7846]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3000 Loss: 0.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  65%|██████▍   | 3001/4621 [28:15<53:24,  1.98s/it, batch_loss=0.7846]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Dites-moi de la maison ? ? ? ? ? ? ? ? ?out ? ? ?ou ? ? ?ou ? ? ?ou ? ? \n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  69%|██████▉   | 3200/4621 [29:58<11:52,  1.99it/s, batch_loss=0.7790]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3200 Loss: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  69%|██████▉   | 3201/4621 [30:02<43:30,  1.84s/it, batch_loss=0.7790]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrais-nous aller la maison ? ? ? ? ?ous ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  74%|███████▎  | 3400/4621 [31:56<11:39,  1.75it/s, batch_loss=0.7898]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3400 Loss: 0.7898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  74%|███████▎  | 3401/4621 [32:01<41:32,  2.04s/it, batch_loss=0.7898]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrait-il me trouver la même ? ? ?e ?outrier ?ous ?ouirir\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  78%|███████▊  | 3600/4621 [33:45<08:42,  1.96it/s, batch_loss=0.7506]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3600 Loss: 0.7506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  78%|███████▊  | 3601/4621 [33:49<32:07,  1.89s/it, batch_loss=0.7506]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Serait-on de la maison ? de la maison ? de la taille ?outer ?ondrire ?ondririre ?s ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  82%|████████▏ | 3800/4621 [35:32<06:31,  2.10it/s, batch_loss=0.7837]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 3800 Loss: 0.7837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  82%|████████▏ | 3801/4621 [35:36<25:16,  1.85s/it, batch_loss=0.7837]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Sera-t-on de la même ? ? ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  87%|████████▋ | 4000/4621 [37:19<04:33,  2.27it/s, batch_loss=0.7616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4000 Loss: 0.7616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  87%|████████▋ | 4001/4621 [37:24<19:02,  1.84s/it, batch_loss=0.7616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Cela nous avons-nous rencontrer la maison ? ? ? ?out ? ? ? ?as ?oute ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  91%|█████████ | 4200/4621 [39:05<03:48,  1.85it/s, batch_loss=0.6382]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4200 Loss: 0.6382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  91%|█████████ | 4201/4621 [39:10<12:46,  1.82s/it, batch_loss=0.6382]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrions-nous aller le même ? ? ? ? ? ? ? tout perdrire ?u ?ontrert ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  95%|█████████▌| 4400/4621 [40:55<01:44,  2.11it/s, batch_loss=0.7308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4400 Loss: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:  95%|█████████▌| 4401/4621 [41:00<06:48,  1.86s/it, batch_loss=0.7308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrait-il aller la malle ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|█████████▉| 4600/4621 [42:50<00:09,  2.24it/s, batch_loss=0.7967]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Batch 4600 Loss: 0.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|█████████▉| 4601/4621 [42:55<00:39,  1.98s/it, batch_loss=0.7967]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eval (should we go...): Devrions-nous aller le mal ? ? ? ? ? ?\n",
      "  -------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 4621/4621 [43:07<00:00,  1.79it/s, batch_loss=0.7895]\n",
      "Validation: 100%|██████████| 513/513 [01:28<00:00,  5.78it/s, val_loss=0.646]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Summary: Avg Train Loss: 0.8604, Avg Val Loss: 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_loop():\n",
    "    transformer.train()\n",
    "    transformer.to(device)\n",
    "    #total_loss = 0\n",
    "    num_epochs = 2 \n",
    "\n",
    "\n",
    "    print(f\"Training on device: {device}\") \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"--- Epoch {epoch+1}/{num_epochs} ---\")\n",
    "        transformer.train() \n",
    "        total_epoch_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1} Training')\n",
    "\n",
    "        for batch_num, batch in enumerate(progress_bar):\n",
    "            english_batch, french_batch = batch\n",
    "            english_batch = english_batch.to(device) \n",
    "            french_batch = french_batch.to(device) \n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # 2. Forward Pass \n",
    "            output = transformer(english_batch, french_batch)\n",
    "            # output shape: [batch_size, tgt_len-1, tgt_vocab_size]\n",
    "\n",
    "            loss = loss_fn(output, french_batch[:, 1:], criterion)\n",
    "\n",
    "            # 4. Backward Pass\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Gradient Clipping\n",
    "            torch.nn.utils.clip_grad_norm_(transformer.parameters(), clip_grad_norm)\n",
    "\n",
    "            # 6. Optimizer Step\n",
    "            optim.step()\n",
    "\n",
    "            total_epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({'batch_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            if batch_num > 0 and batch_num % 200 == 0: \n",
    "                print(f\"\\n  Batch {batch_num} Loss: {loss.item():.4f}\")\n",
    "                transformer.eval()\n",
    "                with torch.no_grad():\n",
    "  \n",
    "                    input_sentence = \"should we go to the mall?\" # a fixed sentence for eval\n",
    "                    input_tokenized = [START_TOKEN] + tokenize(input_sentence, english_vocabulary) + [END_TOKEN]\n",
    "                    input_numericalized = [en_to_index.get(token, en_to_index.get(UNKNOWN_TOKEN, 0)) for token in input_tokenized]\n",
    "                    input_tensor = torch.tensor(input_numericalized).unsqueeze(0).to(device)\n",
    "\n",
    "                    start_symbol_idx = fr_to_index.get(START_TOKEN)\n",
    "                    if start_symbol_idx is None:\n",
    "                       raise ValueError(\"START_TOKEN not found in fr_to_index mapping\")\n",
    "\n",
    "                    output_indices = transformer.greedy_decode(input_tensor, max_len=max_sequence_length, start_symbol=start_symbol_idx)[0].cpu().numpy()\n",
    "\n",
    "                  \n",
    "                    pad_idx = fr_to_index.get(PADDING_TOKEN)\n",
    "                    end_idx = fr_to_index.get(END_TOKEN)\n",
    "\n",
    "                    predicted_sentence_chars = [\n",
    "                        index_to_fr[idx] for idx in output_indices\n",
    "                        if idx != pad_idx and idx != start_symbol_idx and idx != end_idx and idx in index_to_fr\n",
    "                    ]\n",
    "                    predicted_sentence = \"\".join(predicted_sentence_chars)\n",
    "                    print(f\"  Eval (should we go...): {predicted_sentence}\")\n",
    "                    print(\"  -------------------------------------------\")\n",
    "                transformer.train() # Set back to train mode\n",
    "\n",
    "        avg_train_loss = total_epoch_loss / len(train_loader)\n",
    "        avg_val_loss = val_loop() \n",
    "        print(f\"Epoch {epoch+1} Summary: Avg Train Loss: {avg_train_loss:.4f}, Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "def val_loop(): # Validation loop\n",
    "    transformer.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar_val = tqdm(val_loader, desc=f'Validation')\n",
    "        for batch_idx, batch in enumerate(progress_bar_val):\n",
    "            english_batch, french_batch = batch\n",
    "            english_batch = english_batch.to(device)\n",
    "            french_batch = french_batch.to(device)\n",
    "\n",
    "            output = transformer(english_batch, french_batch)\n",
    "            val_loss = loss_fn(output, french_batch[:, 1:], criterion) \n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "            progress_bar_val.set_postfix({'val_loss': val_loss.item()})\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    return avg_val_loss\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu') \n",
    "    train_loop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "def translate(eng_sentence_text): \n",
    "    \"\"\"Translates an English sentence to French using greedy decoding.\"\"\"\n",
    "    with torch.no_grad(): # Disable gradients during inference\n",
    "      \n",
    "        input_tokenized = [START_TOKEN] + tokenize(eng_sentence_text, english_vocabulary) + [END_TOKEN] # Tokenize input sentence\n",
    "        input_numericalized = [en_to_index[token] for token in input_tokenized] # Numericalize input tokens\n",
    "        input_tensor = torch.tensor(input_numericalized).unsqueeze(0).to(device) # Create tensor, add batch dimension, move to device\n",
    "\n",
    "        # Greedy Decode \n",
    "        output_indices = transformer.greedy_decode(\n",
    "            input_tensor, max_len=max_sequence_length, start_symbol=fr_to_index[START_TOKEN]\n",
    "        )[0].cpu().numpy() \n",
    "\n",
    "        # 3. Convert Output Indices to French Sentence\n",
    "        predicted_sentence_chars = []\n",
    "        for idx in output_indices:\n",
    "            if idx == fr_to_index[END_TOKEN]: \n",
    "                break\n",
    "            predicted_sentence_chars.append(index_to_fr[idx]) \n",
    "\n",
    "        predicted_sentence = \"\".join(predicted_sentence_chars) \n",
    "        return predicted_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Input: what should we do when the day starts?\n",
      "French Translation: <SOS>Ce que devrais-nous faire le dire ?\n"
     ]
    }
   ],
   "source": [
    "english_input = \"what should we do when the day starts?\"\n",
    "french_translation = translate(english_input)\n",
    "print(f\"English Input: {english_input}\")\n",
    "print(f\"French Translation: {french_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Input: what do you think about the book?\n",
      "French Translation: <SOS>Ce que vous pensez-vous ?\n"
     ]
    }
   ],
   "source": [
    "english_input = \"what do you think about the book?\"\n",
    "french_translation = translate(english_input)\n",
    "print(f\"English Input: {english_input}\")\n",
    "print(f\"French Translation: {french_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Input: where are you going?\n",
      "French Translation: <SOS>Où vous avez en train de matin ?\n"
     ]
    }
   ],
   "source": [
    "english_input = \"where are you going?\"\n",
    "french_translation = translate(english_input)\n",
    "print(f\"English Input: {english_input}\")\n",
    "print(f\"French Translation: {french_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Input: I want a new book.\n",
      "French Translation: <SOS>Je veux un livre un livre.\n"
     ]
    }
   ],
   "source": [
    "english_input = \"I want a new book.\"\n",
    "french_translation = translate(english_input)\n",
    "print(f\"English Input: {english_input}\")\n",
    "print(f\"French Translation: {french_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
